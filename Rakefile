#!/usr/bin/env rake
# frozen_string_literal: true

require 'json'
require_relative 'lib/claude_history_to_obsidian'

desc 'Run all tests with coverage report'
task 'test:coverage' do
  sh "bundle exec ruby -I lib:test test/run_all_tests.rb"
  puts "\nğŸ“Š Coverage report: coverage/index.html"
  sh 'open coverage/index.html' if RUBY_PLATFORM.include?('darwin')
end

desc 'Run all tests'
task :test do
  test_files = Dir.glob('test/test_*.rb').reject { |f| f.include?('test_helper') }.join(' ')
  sh "bundle exec ruby -I lib:test -rtest/unit #{test_files}"
end

task default: :test

namespace :code do
  desc 'Bulk import past Claude Code sessions from ~/.claude/projects/'
  task :bulk_import do
    projects_dir = ENV.fetch('CLAUDE_PROJECTS_DIR', File.expand_path('~/.claude/projects/'))

    unless Dir.exist?(projects_dir)
      puts "Error: #{projects_dir} does not exist"
      exit 1
    end

    puts 'ğŸ”„ Code bulk import...'
    puts "ğŸ“ Source: #{projects_dir}"

    count = 0
    errors = 0

    # Ctrl+C ã§çµ‚äº†
    Signal.trap('INT') do
      puts "\nâš ï¸  Interrupt received, stopping import..."
      exit 130
    end

    begin
      # JSONL ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«å‡¦ç†
      last_project = nil
      Dir.glob("#{projects_dir}/**/*.jsonl").each do |jsonl_path|
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’æŠ½å‡º
        project_name = extract_project_name(jsonl_path)

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒå¤‰ã‚ã£ãŸã‚‰è¡¨ç¤º
        if project_name != last_project
          puts "ğŸ“‚ #{project_name}"
          last_project = project_name
        end

        sessions = parse_and_group_jsonl(jsonl_path)

        sessions.each do |session_id, session_data|
          begin
            relative_path = process_session(session_id, session_data)
            puts relative_path
            count += 1
          rescue StandardError => e
            errors += 1
            warn "Error processing session #{session_id}: #{e.message}"
          end
        end
      end

      puts "\nâœ“ Code import completed: #{count} sessions imported, #{errors} errors"
    rescue StandardError => e
      puts "âœ— Code import failed: #{e.message}"
      exit 1
    ensure
      Signal.trap('INT', 'DEFAULT')
    end
  end
end

namespace :web do
  desc 'Bulk import Claude Web Export conversations.json to Obsidian (CONVERSATIONS_JSON=/path/to/file or ~/Downloads/conversations.json)'
  task :bulk_import do
    conversations_json = ENV['CONVERSATIONS_JSON'] || File.expand_path('~/Downloads/conversations.json')

    unless File.exist?(conversations_json)
      warn "Error: #{conversations_json} does not exist"
      exit 1
    end

    begin
      puts 'ğŸ”„ Web bulk import...'
      puts "ğŸ“ Reading: #{conversations_json}"

      # Ruby ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŒ‡å®šã§èª­ã¿è¾¼ã‚€ï¼ˆJSON å…¨ä½“ã‚’ãƒ‘ãƒ¼ã‚¹ï¼‰
      # conversations.json (UTF-8, invalid:replace) â†’ Ruby JSON parse â†’ process_transcript
      file_content = File.read(conversations_json, encoding: 'UTF-8')
      # ç„¡åŠ¹ãª UTF-8 ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ ? ã«ç½®æ›
      file_content = file_content.encode('UTF-8', invalid: :replace)

      conversations = JSON.parse(file_content)
      raise "Expected Array in conversations.json" unless conversations.is_a?(Array)

      count = 0
      conversations.each do |conversation|
        begin
          relative_path = process_web_conversation(conversation)
          puts relative_path
          count += 1
        rescue StandardError => e
          warn "WARNING: Failed to process conversation: #{e.message}"
          # æ¬¡ã®ä¼šè©±ã‚’å‡¦ç†ç¶™ç¶šï¼ˆéãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
        end
      end

      puts "\nâœ“ Web import completed: #{count} conversations processed"

    rescue JSON::ParserError => e
      warn "âœ— Failed to parse JSON: #{e.message}"
      exit 1
    rescue StandardError => e
      warn "âœ— Web import failed: #{e.message}"
      exit 1
    end
  end
end

private

def parse_and_group_jsonl(path)
  sessions = {}

  # UTF-8 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã‚€ï¼ˆinvalid byte ã¯ç½®æ›ï¼‰
  File.open(path, 'r:UTF-8', invalid: :replace) do |file|
    file.each_line do |line|
      next if line.strip.empty?

      begin
        parsed = JSON.parse(line)
        session_id = parsed['sessionId']
        cwd = parsed['cwd']
        timestamp = parsed['timestamp']
        message = parsed['message']

        next unless session_id && cwd && message

        sessions[session_id] ||= { messages: [], cwd: cwd }

        # content ãŒé…åˆ—ã®å ´åˆï¼ˆAssistant ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        content = message['content']
        if content.is_a?(Array)
          content = content.map { |c| c.is_a?(Hash) && c['type'] == 'text' ? c['text'] : c.to_s }.join("\n")
        end

        sessions[session_id][:messages] << {
          'role' => message['role'],
          'content' => content,
          'timestamp' => timestamp
        }
      rescue JSON::ParserError => e
        # JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        warn "WARNING: Failed to parse JSON in #{path}: #{e.message[0..100]}"
        next
      end
    end
  end

  sessions
end

def process_session(session_id, session_data)
  messages = session_data[:messages]
  cwd = session_data[:cwd]

  # ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ
  first_msg_timestamp = extract_first_message_timestamp(messages)
  transcript = {
    'session_id' => session_id,
    'cwd' => cwd,
    'messages' => messages,
    '_first_message_timestamp' => first_msg_timestamp
  }.compact

  # ClaudeHistoryToObsidian ã‚’ç›´æ¥å‘¼ã³å‡ºã™
  processor = ClaudeHistoryToObsidian.new
  relative_path = processor.process_transcript(
    project_name: File.basename(cwd),
    cwd: cwd,
    session_id: session_id,
    transcript: transcript,
    messages: messages
  )

  relative_path
end

def extract_first_message_timestamp(messages)
  return nil unless messages && messages.length.positive?

  first_msg = messages.first
  return nil unless first_msg['timestamp']

  # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¿ã‚¤ãƒ : UTC â†’ getlocal ã§å¤‰æ›ã—ã¦ã‹ã‚‰æ•´å½¢
  utc_time = Time.parse(first_msg['timestamp']).utc
  local_time = utc_time.getlocal
  local_time.strftime('%Y%m%d-%H%M%S')
rescue StandardError => e
  warn "WARNING: Failed to extract timestamp: #{e.message}"
  nil
end

def process_web_conversation(conversation)
  # conversations.json ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡º
  session_id = conversation['uuid']
  conversation_name = conversation['name'] || 'conversation'
  chat_messages = conversation['chat_messages'] || []

  # ç©ºã®ä¼šè©±ã¯ã‚¹ã‚­ãƒƒãƒ—
  return if chat_messages.empty?

  # chat_messages ã‚’ transcript å½¢å¼ã«å¤‰æ›
  # Note: Claude Web uses 'sender' field instead of 'role', and 'human' instead of 'user'
  messages = chat_messages.map do |msg|
    {
      'role' => msg['sender'] == 'human' ? 'user' : msg['sender'],
      'content' => msg['content'],
      'timestamp' => msg['created_at']
    }
  end

  # ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ
  timestamp = extract_first_message_timestamp(messages)
  transcript = {
    'session_id' => session_id,
    'cwd' => Dir.pwd,
    'messages' => messages,
    '_first_message_timestamp' => timestamp
  }.compact

  # conversation_name ã‚’ã‚¹ãƒ©ãƒƒã‚°åŒ–ã—ã¦ project_name ã¨ã—ã¦ä½¿ç”¨
  project_name = slugify_name(conversation_name)

  processor = ClaudeHistoryToObsidian.new
  relative_path = processor.process_transcript(
    project_name: project_name,
    cwd: Dir.pwd,
    session_id: session_id,
    transcript: transcript,
    messages: messages,
    source: 'web'
  )

  relative_path
end

def extract_project_name(jsonl_path)
  # ~/.claude/projects/{project-name}/{file}.jsonl ã‹ã‚‰project-nameã‚’æŠ½å‡º
  parts = jsonl_path.split('/')
  projects_index = parts.index('projects')
  return 'unknown' unless projects_index

  parts[projects_index + 1] || 'unknown'
end

def slugify_name(name)
  # æœ€åˆã®30æ–‡å­—ã‚’å–å¾—
  text = name[0..29]

  normalized = text
               .downcase
               .gsub(/[^a-z0-9]+/, '-')
               .sub(/^-+/, '')
               .sub(/-+$/, '')

  normalized.empty? ? 'conversation' : normalized
end
